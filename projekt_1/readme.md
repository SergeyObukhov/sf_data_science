# Проект 1. Анализ вакансий на hh.ru  
  
## Оглавление  
[1. Описание проекта](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#описание-проекта)  
[2. Какой кейс решаем?](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#какой-кейс-решаем)  
[3. Краткая информация о данных](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#краткая-информация-о-данных)  
[4. Этапы работы над проектом](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#этапы-работы-над-проектом)  
[5. Результаты](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#результаты)  
[6. Выводы](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#выводы)  
  
### Описание проекта  
Компания *HeadHunter* хочет построить модель, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе.

Проект решает часть этой бизнес-задачи: *Подготовка, и анализ резюме соискателей*
  
:arrow_up: [к оглавлению](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#оглавление)  
  
  
### Какой кейс решаем?  
Нужно преобразовать, исследовать и очистить данные соискателей вакансий на hh.ru.  
  
**Условия соревнования:**  
...
  
**Метрика качества**  
Результаты оцениваются контрольными вопросами и *code*-ревью ментором проекта.
  
**Что практикуем**  
- Учимся конструировать новые признаки, преобразовывая существующие.  
- Практикуем визуализацию данных, исследуя зависимости.
- Учимся чистить данные.
  
:arrow_up: [к оглавлению](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#оглавление)  

### Краткая информация о данных  
В нашем распоряжении база резюме, выгруженная с сайта поиска вакансий **HH.RU**. Ссылка: [***dst-3.0_16_1_hh_database.csv***](https://disk.yandex.ru/d/GByz1zdEB5nRpw).

А также данные о курсах валют, выгруженные с сайта финансовой информации **MDF.RU**. Ссылка: [***ExchangeRates.csv***](https://disk.yandex.ru/d/UU-Ejw8S7fZCog).
  
:arrow_up: [к оглавлению](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#оглавление)  
  
  
### Этапы работы над проектом:  
1. **Базовый анализ структуры данных:** оцениваем размерность исходных данных, знакомимся с признаками и их структурой, проверяем основную статистическую информацию.
2. **Преобразование данных:** создаём новые признаки, преобразуя имеющиеся.
3. **Разведывательный анализ:** строим графики, и выявляем связи между признаками, закономерности, ищем аномалии и другие дефекты данных.
4. **Очистка данных:** удаляем дубликаты, пропуски данных, аномалии и выбросы.
  
:arrow_up: [к оглавлению](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#оглавление)  
  
  
### Результаты  
- Я попрактиковался в feature engineering.
- Я отработал приёмы визуализации зависимостей.  
- Я потренировался в очистке данных.
  
:arrow_up: [к оглавлению](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#оглавление)  
  
  
### Выводы  
Я справился с поставленной задачей:
проанализировал данные с сайта hh.ru, нашел зависимости, и сделал выводы. 
  
:arrow_up: [к оглавлению](https://github.com/SergeyObukhov/sf_data_science/tree/main/projekt_1#оглавление)